{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74497d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config (update these variables based on your GCP project and naming conventions)\n",
    "\n",
    "GCP_PROJECT_ID           = 'dz-apps'        # Google Cloud Project ID\n",
    "BQ_DATASET               = 'zdatasets'      # Name of BigQuery Dataset to create (if it does not exist)\n",
    "BQ_MODEL_NAME            = 'logistic_model' # Name of BigQuery model that will be trained\n",
    "GCS_BUCKET               = 'bqml_vertex'    # Google Cloud Storage Bucket to be created\n",
    "GCS_LOCATION             = 'us-central1'    # Google Cloud Storage Location\n",
    "VERTEX_LOCATION          = 'us-central1'\n",
    "VERTEX_MODEL_NAME        = 'bqml-to-vertex'\n",
    "VERTEX_SERVING_CONTAINER = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest' # https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e750924",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6398e",
   "metadata": {},
   "source": [
    "## **BigQuery ML model deployment to Vertex AI**\n",
    "References: \n",
    "* [Vertex/AI Platform SDK](https://github.com/googleapis/python-aiplatform)\n",
    "* [BQML Exporting Models](https://cloud.google.com/bigquery-ml/docs/exporting-models#bq)\n",
    "* [BQML Logistic Example](https://cloud.google.com/bigquery-ml/docs/logistic-regression-prediction)\n",
    "* [BQML Model Types](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#model_type)\n",
    "* [Codelab example that I modified for this notebook](https://codelabs.developers.google.com/codelabs/bqml-vertex-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a7542b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform==1.0.1\n",
      "  Downloading google_cloud_aiplatform-1.0.1-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.22.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.1) (1.26.3)\n",
      "Requirement already satisfied: google-cloud-storage<2.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.1) (1.38.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.1) (20.9)\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.1) (1.18.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.1) (2.17.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (2.25.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (1.53.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (2021.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (3.16.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (1.30.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (1.38.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (4.7.2)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.1) (1.3.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.1) (1.6.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.1) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.1) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.1) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform==1.0.1) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.1) (2.10)\n",
      "Installing collected packages: google-cloud-aiplatform\n",
      "Successfully installed google-cloud-aiplatform-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dacc0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bf1cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BQ client\n",
    "try:\n",
    "    bq_client = bigquery.Client()\n",
    "except Exception as e: \n",
    "    print('[ EXCEPTION ] {}'.format(e))\n",
    "\n",
    "QUERY = f'''\n",
    "CREATE OR REPLACE MODEL\n",
    "  `{GCP_PROJECT_ID}.{BQ_DATASET}.{BQ_DATASET}` OPTIONS(model_type='LOGISTIC_REG',\n",
    "    input_label_cols=['default_payment_next_month']) AS\n",
    "SELECT\n",
    "  limit_balance,\n",
    "  sex,\n",
    "  education_level,\n",
    "  marital_status,\n",
    "  age,\n",
    "  pay_0,\n",
    "  pay_2,\n",
    "  pay_3,\n",
    "  pay_4,\n",
    "  pay_5,\n",
    "  pay_6,\n",
    "  bill_amt_1,\n",
    "  bill_amt_2,\n",
    "  bill_amt_3,\n",
    "  bill_amt_4,\n",
    "  bill_amt_5,\n",
    "  bill_amt_6,\n",
    "  pay_amt_1,\n",
    "  pay_amt_2,\n",
    "  pay_amt_3,\n",
    "  pay_amt_4,\n",
    "  pay_amt_5,\n",
    "  pay_amt_6,\n",
    "  default_payment_next_month\n",
    "FROM\n",
    "  `bigquery-public-data.ml_datasets.credit_card_default`\n",
    "'''\n",
    "query_job = bq_client.query(QUERY)\n",
    "rows = query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b6cc494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Successfully created bqml_vertex at us-central1\n"
     ]
    }
   ],
   "source": [
    "# Create Google Cloud Storage bucket\n",
    "\n",
    "def gcs_create_bucket(bucket_name, location='us-central1', storage_class=\"STANDARD\"):\n",
    "    try:\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        bucket.storage_class = storage_class # STANDARD, NEARLINE, COLDLINE, ARCHIVE\n",
    "        bucket.create(location=location) # Location can be 'us', 'us-central1', 'us-east4'\n",
    "        print('[ INFO ] Successfully created {} at {}'.format(bucket_name, location))\n",
    "    except Exception as e:\n",
    "        print('[ EXCEPTION ] {}'.format(e))\n",
    "\n",
    "gcs_create_bucket(GCS_BUCKET, GCS_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8694069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export BQML Model to the newly created Cloud Storage Bucket\n",
    "\n",
    "QUERY = f'''\n",
    "EXPORT MODEL `{GCP_PROJECT_ID}.{BIGQUERY_DATASET}.{BQ_MODEL_NAME}`\n",
    "OPTIONS(URI = 'gs://{GCS_BUCKET}/model-assets/')\n",
    "'''\n",
    "query_job = bq_client.query(QUERY)\n",
    "rows = query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Model (that has been exported to Google Cloud Storage) into Vertex AI\n",
    "\n",
    "def upload_model(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    display_name: str,\n",
    "    serving_container_image_uri: str,\n",
    "    artifact_uri: Optional[str] = None,\n",
    "    serving_container_predict_route: Optional[str] = None,\n",
    "    serving_container_health_route: Optional[str] = None,\n",
    "    description: Optional[str] = None,\n",
    "    serving_container_command: Optional[Sequence[str]] = None,\n",
    "    serving_container_args: Optional[Sequence[str]] = None,\n",
    "    serving_container_environment_variables: Optional[Dict[str, str]] = None,\n",
    "    serving_container_ports: Optional[Sequence[int]] = None,\n",
    "    instance_schema_uri: Optional[str] = None,\n",
    "    parameters_schema_uri: Optional[str] = None,\n",
    "    prediction_schema_uri: Optional[str] = None,\n",
    "    explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
    "    explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
    "    sync: bool = True,\n",
    "):\n",
    "    \n",
    "    aiplatform.init(project=project, location=location)\n",
    "    \n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=display_name,\n",
    "        artifact_uri=artifact_uri,\n",
    "        serving_container_image_uri=serving_container_image_uri,\n",
    "        serving_container_predict_route=serving_container_predict_route,\n",
    "        serving_container_health_route=serving_container_health_route,\n",
    "        instance_schema_uri=instance_schema_uri,\n",
    "        parameters_schema_uri=parameters_schema_uri,\n",
    "        prediction_schema_uri=prediction_schema_uri,\n",
    "        description=description,\n",
    "        serving_container_command=serving_container_command,\n",
    "        serving_container_args=serving_container_args,\n",
    "        serving_container_environment_variables=serving_container_environment_variables,\n",
    "        serving_container_ports=serving_container_ports,\n",
    "        explanation_metadata=explanation_metadata,\n",
    "        explanation_parameters=explanation_parameters,\n",
    "        sync=sync,\n",
    "    )\n",
    "    \n",
    "    model.wait()\n",
    "    \n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "187671b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/492854496121/locations/us-central1/models/530307652215898112/operations/8475334968938070016\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/492854496121/locations/us-central1/models/530307652215898112\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/492854496121/locations/us-central1/models/530307652215898112')\n"
     ]
    }
   ],
   "source": [
    "# Pre-built Model Serving Containers:\n",
    "# https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "\n",
    "aiplatform.init(project=GCP_PROJECT_ID, location=VERTEX_LOCATION)\n",
    "    \n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=VERTEX_MODEL_NAME,\n",
    "    artifact_uri=f'gs://{GCS_BUCKET}/model-assets/',\n",
    "    serving_container_image_uri=VERTEX_SERVING_CONTAINER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c79e7d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/492854496121/locations/us-central1/endpoints/1907890168702959616/operations/2616151853729054720\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/492854496121/locations/us-central1/endpoints/1907890168702959616\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/492854496121/locations/us-central1/endpoints/1907890168702959616')\n",
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/492854496121/locations/us-central1/endpoints/1907890168702959616\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/492854496121/locations/us-central1/endpoints/1907890168702959616/operations/1004707612060549120\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/492854496121/locations/us-central1/endpoints/1907890168702959616\n"
     ]
    }
   ],
   "source": [
    "# Deploy Vertex Model as an Endpoint\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=f'''{VERTEX_MODEL_NAME}-endpoint''',\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de92b14",
   "metadata": {},
   "source": [
    "## **Get Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5923c78",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "request() got an unexpected keyword argument 'HEADER'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-9226a11b681a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m }\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'https://{VERTEX_REGION}-prediction-aiplatform.googleapis.com/v1alpha1/projects/{GCP_PROJECT_ID}/locations/{VERTEX_REGION}/endpoints/{VERTEX_ENDPOINT_ID}:predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPAYLOAD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHEADER\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEADER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} - {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: request() got an unexpected keyword argument 'HEADER'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "GCP_PROJECT_ID      = GCP_PROJECT_ID  # 'dz-apps'\n",
    "VERTEX_REGION       = VERTEX_LOCATION # 'us-central1'\n",
    "VERTEX_ENDPOINT_ID  = '1907890168702959616'\n",
    "ACCESS_TOKEN        = 'ya29.a0AfH6SMAnM8jdDzbxNJb3LyfArR0-k41L3sKxaizAlnbhe5ui-3ggO9A8cZLqY4JDNQ3Z1gBsZhIseTUntLb08WAH8hEL6zatM-9-JW0EM8VmPEUKCvPhOjm1UNytrQ07tYaF4kYL1D1G3Rs-Og4K-ff-kXrOK7ec_nWZ9gmUzXPUX6N05hI6QhITbhNLKGKqOl8fq2G2LlGMO5oLIUcBUCPoRVfydMX9hllrWlCGUiwJTfZaJ-VUr_Ladl_k-9Jk1preNrc'  # $(gcloud auth print-access-token)\n",
    "HEADER = {\"Authorization\": f\"Bearer {ACCESS_TOKEN}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "PAYLOAD = {\n",
    "  \"instances\": [\n",
    "    {\"age\": 39,\n",
    "    \"bill_amt_1\": 47174,\n",
    "    \"bill_amt_2\": 47974,\n",
    "    \"bill_amt_3\": 48630,\n",
    "    \"bill_amt_4\": 50803,\n",
    "    \"bill_amt_5\": 30789,\n",
    "    \"bill_amt_6\": 15874,\n",
    "    \"education_level\": \"1\",\n",
    "    \"limit_balance\": 50000,\n",
    "    \"marital_status\": \"2\",\n",
    "    \"pay_0\": 0,\n",
    "    \"pay_2\":0,\n",
    "    \"pay_3\": 0,\n",
    "    \"pay_4\": 0,\n",
    "    \"pay_5\": \"0\",\n",
    "    \"pay_6\": \"0\",\n",
    "    \"pay_amt_1\": 1800,\n",
    "    \"pay_amt_2\": 2000,\n",
    "    \"pay_amt_3\": 3000,\n",
    "    \"pay_amt_4\": 2000,\n",
    "    \"pay_amt_5\": 2000,\n",
    "    \"pay_amt_6\": 2000,\n",
    "    \"sex\": \"1\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = requests.post(f'https://{VERTEX_REGION}-prediction-aiplatform.googleapis.com/v1alpha1/projects/{GCP_PROJECT_ID}/locations/{VERTEX_REGION}/endpoints/{VERTEX_ENDPOINT_ID}:predict', json=PAYLOAD, HEADER=HEADER)\n",
    "\n",
    "print('{} - {}'.format(response.status_code, response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cfa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
