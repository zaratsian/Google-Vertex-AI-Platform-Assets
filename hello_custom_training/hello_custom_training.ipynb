{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funky-column",
   "metadata": {},
   "source": [
    "## Hello custom training: Training a custom image classification model\n",
    "\n",
    "Reference: https://cloud.google.com/ai-platform-unified/docs/tutorials/image-recognition-custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "consecutive-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "IMG_WIDTH = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-referral",
   "metadata": {},
   "source": [
    "## User Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "final-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_project = 'zproject201807'\n",
    "gcp_region  = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-concrete",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "congressional-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environ variables\n",
    "\n",
    "os.environ['GCP_PROJECT']=gcp_project\n",
    "\n",
    "gcp_bucket_path = '{}-ai'.format(gcp_project)\n",
    "\n",
    "os.environ['AIP_MODEL_DIR']='{}/output'.format(gcp_bucket_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pursuant-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image):\n",
    "    \"\"\"Normalizes image.\n",
    "    \n",
    "    * Resizes image to IMG_WIDTH x IMG_WIDTH pixels\n",
    "    * Casts values from `uint8` to `float32`\n",
    "    * Scales values from [0, 255] to [0, 1]\n",
    "    \n",
    "    Returns:\n",
    "      A tensor with shape (IMG_WIDTH, IMG_WIDTH, 3). (3 color channels)\n",
    "    \"\"\"\n",
    "    image = tf.image.resize_with_pad(image, IMG_WIDTH, IMG_WIDTH)\n",
    "    return image / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "willing-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img_and_label(image, label):\n",
    "    \"\"\"Normalizes image and label.\n",
    "    \n",
    "    * Performs normalize_img on image\n",
    "    * Passes through label unchanged\n",
    "    \n",
    "    Returns:\n",
    "      Tuple (image, label) where\n",
    "      * image is a tensor with shape (IMG_WIDTH, IMG_WIDTH, 3). (3 color\n",
    "        channels)\n",
    "      * label is an unchanged integer [0, 4] representing flower type\n",
    "    \"\"\"\n",
    "    return normalize_img(image), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mechanical-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'AIP_MODEL_DIR' not in os.environ:\n",
    "    raise KeyError(\n",
    "        'The `AIP_MODEL_DIR` environment variable has not been' +\n",
    "        'set. See https://cloud.google.com/ai-platform-unified/docs/tutorials/image-recognition-custom/training'\n",
    "    )\n",
    "\n",
    "output_directory = os.environ['AIP_MODEL_DIR']\n",
    "output_directory = os.environ['AIP_MODEL_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "another-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load('tf_flowers:3.*.*',\n",
    "                    split='train',\n",
    "                    try_gcs=True,\n",
    "                    shuffle_files=True,\n",
    "                    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "computational-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(normalize_img_and_label,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "advised-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(128)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "designing-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,\n",
    "                           3,\n",
    "                           padding='same',\n",
    "                           activation='relu',\n",
    "                           input_shape=(IMG_WIDTH, IMG_WIDTH, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5)  # 5 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "opening-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "relevant-south",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 25s 855ms/step - loss: 1.3816 - accuracy: 0.4084\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 1.0782 - accuracy: 0.5678\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 22s 770ms/step - loss: 0.9334 - accuracy: 0.6406\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 22s 748ms/step - loss: 0.8290 - accuracy: 0.6820\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 22s 748ms/step - loss: 0.7351 - accuracy: 0.7270\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 22s 745ms/step - loss: 0.6382 - accuracy: 0.7613\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 22s 752ms/step - loss: 0.5451 - accuracy: 0.7929\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 22s 765ms/step - loss: 0.4490 - accuracy: 0.8420\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 22s 758ms/step - loss: 0.3974 - accuracy: 0.8529\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 21s 741ms/step - loss: 0.2950 - accuracy: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f64402e36d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "brazilian-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting SavedModel to: zproject201807-ai/output\n"
     ]
    }
   ],
   "source": [
    "print(f'Exporting SavedModel to: {output_directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pretty-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add softmax layer for intepretability\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "architectural-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: zproject201807-ai/output/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: zproject201807-ai/output/assets\n"
     ]
    }
   ],
   "source": [
    "probability_model.save(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-butler",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
